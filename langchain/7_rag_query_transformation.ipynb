{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T14:46:30.289974Z",
     "start_time": "2024-06-29T14:46:30.286812Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Query\n",
    "\n",
    "### Index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "blog_docs = loader.load()\n",
    "\n",
    "# Split\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=300, chunk_overlap=50\n",
    ")\n",
    "\n",
    "# Make splits\n",
    "splits = text_splitter.split_documents(blog_docs)\n",
    "\n",
    "# Index\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\"),\n",
    ")\n",
    "\n",
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Multi Query: Different Perspectives\n",
    "template = \"\"\"You are an AI language model assistant. Your task is to generate five \n",
    "different versions of the given user question to retrieve relevant documents from a vector \n",
    "database. By generating multiple perspectives on the user question, your goal is to help\n",
    "the user overcome some of the limitations of the distance-based similarity search. \n",
    "Provide these alternative questions separated by newlines. Original question: {question}\"\"\"\n",
    "prompt_perspectives = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "generate_queries = (\n",
    "    prompt_perspectives\n",
    "    | ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    | StrOutputParser()\n",
    "    | (lambda x: x.split(\"\\n\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/clement/Developer/ai/langchain-notebooks/.venv/lib/python3.11/site-packages/langchain_core/_api/beta_decorator.py:87: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
      "  warn_beta(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.load import dumps, loads\n",
    "\n",
    "\n",
    "def get_unique_union(documents: list[list]):\n",
    "    \"\"\"Unique union of retrieved docs\"\"\"\n",
    "    # Flatten list of lists, and convert each Document to string\n",
    "    flattened_docs = [dumps(doc) for sublist in documents for doc in sublist]\n",
    "    # Get unique documents\n",
    "    unique_docs = list(set(flattened_docs))\n",
    "    # Return\n",
    "    return [loads(doc) for doc in unique_docs]\n",
    "\n",
    "\n",
    "# Retrieve\n",
    "question = \"What is task decomposition for LLM agents?\"\n",
    "retrieval_chain = generate_queries | retriever.map() | get_unique_union\n",
    "docs = retrieval_chain.invoke({\"question\": question})\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition for LLM (large language model) agents involves breaking down complex tasks into smaller, manageable subgoals. This process enables the agent to handle complicated tasks more efficiently. There are several methods for task decomposition:\\n\\n1. **Chain of Thought (CoT)**: This prompting technique encourages the model to \"think step by step,\" allowing it to utilize more computation at test time to decompose difficult tasks into simpler steps.\\n\\n2. **Tree of Thoughts**: This approach extends CoT by exploring multiple reasoning possibilities at each step. It decomposes the problem into multiple thought steps and generates various thoughts per step, creating a tree structure that can be searched using breadth-first or depth-first search methods.\\n\\n3. **Prompting Techniques**: Task decomposition can be achieved through simple prompts, such as asking the model for the steps to achieve a goal or subgoals for a specific task.\\n\\n4. **Task-Specific Instructions**: Providing specific instructions tailored to the task, like asking the model to write a story outline for novel writing.\\n\\n5. **Human Inputs**: Involving human guidance to assist in breaking down tasks.\\n\\nOverall, task decomposition is a crucial component that enhances the LLM\\'s ability to manage and solve complex problems effectively.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# RAG\n",
    "template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "final_rag_chain = (\n",
    "    {\"context\": retrieval_chain, \"question\": itemgetter(\"question\")}\n",
    "    | prompt\n",
    "    | ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "final_rag_chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG-Fusion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# RAG-Fusion: Related\n",
    "template = \"\"\"You are a helpful assistant that generates multiple search queries based on a single input query. \\n\n",
    "Generate multiple search queries related to: {question} \\n\n",
    "Output (4 queries):\"\"\"\n",
    "prompt_rag_fusion = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "generate_queries = (\n",
    "    prompt_rag_fusion | model | StrOutputParser() | (lambda x: x.split(\"\\n\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.load import dumps, loads\n",
    "\n",
    "\n",
    "def reciprocal_rank_fusion(results: list[list], k=60):\n",
    "    \"\"\"Reciprocal_rank_fusion that takes multiple lists of ranked documents\n",
    "    and an optional parameter k used in the RRF formula\"\"\"\n",
    "\n",
    "    # Initialize a dictionary to hold fused scores for each unique document\n",
    "    fused_scores = {}\n",
    "\n",
    "    # Iterate through each list of ranked documents\n",
    "    for docs in results:\n",
    "        # Iterate through each document in the list, with its rank (position in the list)\n",
    "        for rank, doc in enumerate(docs):\n",
    "            # Convert the document to a string format to use as a key (assumes documents can be serialized to JSON)\n",
    "            doc_str = dumps(doc)\n",
    "            # If the document is not yet in the fused_scores dictionary, add it with an initial score of 0\n",
    "            if doc_str not in fused_scores:\n",
    "                fused_scores[doc_str] = 0\n",
    "            # Retrieve the current score of the document, if any\n",
    "            previous_score = fused_scores[doc_str]\n",
    "            # Update the score of the document using the RRF formula: 1 / (rank + k)\n",
    "            fused_scores[doc_str] += 1 / (rank + k)\n",
    "\n",
    "    # Sort the documents based on their fused scores in descending order to get the final reranked results\n",
    "    reranked_results = [\n",
    "        (loads(doc), score)\n",
    "        for doc, score in sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    ]\n",
    "\n",
    "    # Return the reranked results as a list of tuples, each containing the document and its fused score\n",
    "    return reranked_results\n",
    "\n",
    "\n",
    "retrieval_chain_rag_fusion = generate_queries | retriever.map() | reciprocal_rank_fusion\n",
    "docs = retrieval_chain_rag_fusion.invoke({\"question\": question})\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition for LLM (large language model) agents involves breaking down complex tasks into smaller, manageable subgoals. This process enables the agent to handle complicated tasks more efficiently. There are several methods for task decomposition:\\n\\n1. **Prompting**: The LLM can be prompted with simple instructions like \"Steps for XYZ\" or \"What are the subgoals for achieving XYZ?\" to guide the decomposition process.\\n\\n2. **Task-specific instructions**: The agent can use specific instructions tailored to the task, such as \"Write a story outline\" for writing a novel.\\n\\n3. **Human inputs**: Human guidance can also be utilized to assist in breaking down tasks.\\n\\nAdditionally, techniques like Chain of Thought (CoT) and Tree of Thoughts extend the capabilities of task decomposition. CoT encourages the model to think step by step, while Tree of Thoughts explores multiple reasoning possibilities at each step, creating a tree structure for more comprehensive planning.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# RAG\n",
    "template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "final_rag_chain = (\n",
    "    {\"context\": retrieval_chain_rag_fusion, \"question\": itemgetter(\"question\")}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "final_rag_chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decomposition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Decomposition\n",
    "template = \"\"\"You are a helpful assistant that generates multiple sub-questions related to an input question. \\n\n",
    "The goal is to break down the input into a set of sub-problems / sub-questions that can be answers in isolation. \\n\n",
    "Generate multiple search queries related to: {question} \\n\n",
    "Output (3 queries):\"\"\"\n",
    "prompt_decomposition = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# LLM\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Chain\n",
    "generate_queries_decomposition = (\n",
    "    prompt_decomposition | model | StrOutputParser() | (lambda x: x.split(\"\\n\"))\n",
    ")\n",
    "\n",
    "# Run\n",
    "question = \"What are the main components of an LLM-powered autonomous agent system?\"\n",
    "questions = generate_queries_decomposition.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. What are the key components of a large language model (LLM) in an autonomous agent system?',\n",
       " '2. How do perception and sensor integration function within an LLM-powered autonomous agent?',\n",
       " '3. What role does decision-making and planning play in the architecture of an LLM-based autonomous agent system?']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "template = \"\"\"Here is the question you need to answer:\n",
    "\n",
    "\\n --- \\n {question} \\n --- \\n\n",
    "\n",
    "Here is any available background question + answer pairs:\n",
    "\n",
    "\\n --- \\n {q_a_pairs} \\n --- \\n\n",
    "\n",
    "Here is additional context relevant to the question: \n",
    "\n",
    "\\n --- \\n {context} \\n --- \\n\n",
    "\n",
    "Use the above context and any background question + answer pairs to answer the question: \\n {question}\n",
    "\"\"\"\n",
    "\n",
    "decomposition_prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "def format_qa_pair(question, answer):\n",
    "    \"\"\"Format Q and A pair\"\"\"\n",
    "\n",
    "    formatted_string = \"\"\n",
    "    formatted_string += f\"Question: {question}\\nAnswer: {answer}\\n\\n\"\n",
    "    return formatted_string.strip()\n",
    "\n",
    "\n",
    "q_a_pairs = \"\"\n",
    "for q in questions:\n",
    "    rag_chain = (\n",
    "        {\n",
    "            \"context\": itemgetter(\"question\") | retriever,\n",
    "            \"question\": itemgetter(\"question\"),\n",
    "            \"q_a_pairs\": itemgetter(\"q_a_pairs\"),\n",
    "        }\n",
    "        | decomposition_prompt\n",
    "        | model\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    answer = rag_chain.invoke({\"question\": q, \"q_a_pairs\": q_a_pairs})\n",
    "    q_a_pair = format_qa_pair(q, answer)\n",
    "    q_a_pairs = q_a_pairs + \"\\n---\\n\" + q_a_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'Question: 1. What are the key components of a large language model (LLM) in an autonomous agent system?\\nAnswer: The key components of a large language model (LLM) in an autonomous agent system include:\\n\\n1. **Planning**: This involves the ability of the agent to break down complex tasks into smaller, manageable subgoals. Effective planning is crucial for handling complicated tasks efficiently.\\n\\n2. **Subgoal and Decomposition**: The agent utilizes techniques like Chain of Thought (CoT) and Tree of Thoughts to decompose tasks into simpler steps. CoT encourages the model to think step by step, while Tree of Thoughts allows for exploring multiple reasoning possibilities at each step.\\n\\n3. **Reflection and Refinement**: The agent can engage in self-criticism and reflection over past actions, learning from mistakes to improve future performance. This iterative process enhances the quality of the results produced by the agent.\\n\\n4. **Memory**: The system may incorporate memory components to retain information over time, which can help in long-term planning and task execution.\\n\\n5. **Natural Language Interface**: The LLM serves as the interface between the agent and external components, relying on natural language for communication. However, the reliability of this interface can be a challenge due to potential formatting errors and inconsistencies in model outputs.\\n\\n6. **Handling Context Limitations**: The LLM must operate within the constraints of finite context length, which limits its ability to include extensive historical information and detailed instructions. Mechanisms like self-reflection can help mitigate some of these limitations.\\n\\nThese components work together to enable the LLM to function effectively as the brain of an autonomous agent, allowing it to solve problems and perform tasks in a structured manner.',\n",
       " \"Question: 2. How do perception and sensor integration function within an LLM-powered autonomous agent?\\nAnswer: In an LLM-powered autonomous agent, perception and sensor integration play crucial roles in enabling the agent to interact effectively with its environment and make informed decisions. Here’s how these functions operate within the system:\\n\\n1. **Perception**: This refers to the agent's ability to interpret and understand sensory data from its environment. The agent receives inputs from various sensors, which could include visual, auditory, or other types of data. These inputs are processed to form a coherent understanding of the current state of the environment. For instance, if the agent is navigating a physical space, it might use visual sensors to detect obstacles and interpret their positions relative to its own.\\n\\n2. **Sensor Integration**: This involves combining data from multiple sensors to create a comprehensive view of the environment. The integration process helps the agent to filter out noise, resolve ambiguities, and enhance the accuracy of its perception. For example, if the agent receives conflicting information from different sensors (e.g., a visual sensor indicating an obstacle and a distance sensor indicating clear space), sensor integration techniques can help determine the most reliable interpretation of the situation.\\n\\n3. **Contextual Awareness**: The LLM utilizes the processed sensory data to inform its planning and decision-making processes. By understanding the current context through perception, the agent can generate appropriate responses or actions. This is where the LLM's capabilities in natural language processing come into play, allowing it to communicate its understanding and intentions effectively.\\n\\n4. **Reflection and Learning**: The agent can also reflect on past interactions and sensory inputs to improve its future performance. By synthesizing memories of previous observations and outcomes, the agent can adjust its behavior based on what it has learned, enhancing its ability to navigate complex environments.\\n\\n5. **Dynamic Adaptation**: The integration of perception and sensor data allows the agent to adapt to changing conditions in real-time. For instance, if new obstacles appear or if the environment changes unexpectedly, the agent can quickly reassess the situation and modify its plans accordingly.\\n\\nIn summary, perception and sensor integration within an LLM-powered autonomous agent enable it to gather, process, and interpret environmental data, facilitating informed decision-making and adaptive behavior in dynamic contexts. This integration is essential for the agent to function effectively as it interacts with the world around it.\",\n",
       " \"Question: 3. What role does decision-making and planning play in the architecture of an LLM-based autonomous agent system?\\nAnswer: Decision-making and planning are fundamental components in the architecture of an LLM-based autonomous agent system, serving as the backbone for how the agent interprets tasks, formulates strategies, and executes actions. Here’s a detailed breakdown of their roles:\\n\\n1. **Task Decomposition**: Planning allows the agent to break down complex tasks into smaller, manageable subgoals. This decomposition is essential for efficient handling of intricate tasks, enabling the agent to approach problems systematically. Techniques such as Chain of Thought (CoT) and Tree of Thoughts facilitate this process by encouraging the agent to think step-by-step and explore multiple reasoning possibilities at each stage.\\n\\n2. **Strategic Decision-Making**: The planning component is responsible for generating a sequence of actions that the agent should take to achieve its goals. This involves evaluating different options, predicting outcomes, and selecting the most effective course of action. The agent must consider various factors, including the current context, available resources, and potential obstacles, to make informed decisions.\\n\\n3. **Self-Reflection and Learning**: Decision-making is enhanced through self-reflection, where the agent evaluates past actions and their outcomes. This iterative process allows the agent to learn from mistakes and refine its strategies for future tasks. By reflecting on previous experiences, the agent can improve its decision-making capabilities, leading to better performance over time.\\n\\n4. **Dynamic Adaptation**: In a dynamic environment, the agent must adapt its plans in real-time based on new information or changes in context. Effective decision-making enables the agent to reassess its strategies and modify its actions accordingly, ensuring that it remains responsive to its surroundings.\\n\\n5. **Integration with Perception**: Decision-making and planning are closely linked to the agent's perception capabilities. The agent relies on sensory data to inform its understanding of the environment, which in turn influences its planning and decision-making processes. By integrating perception with planning, the agent can generate contextually appropriate responses and actions.\\n\\n6. **Handling Complexity and Uncertainty**: The architecture must account for the inherent complexity and uncertainty in real-world tasks. Planning mechanisms help the agent navigate these challenges by providing structured approaches to problem-solving, even when faced with unexpected errors or ambiguous situations.\\n\\nIn summary, decision-making and planning are critical for the effective functioning of an LLM-based autonomous agent system. They enable the agent to break down tasks, make informed choices, learn from experiences, adapt to changes, and integrate sensory information, all of which contribute to the agent's ability to operate autonomously and efficiently in complex environments.\"]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_a_pairs.split(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Decision-making and planning are fundamental components in the architecture of an LLM-based autonomous agent system, serving as the backbone for how the agent interprets tasks, formulates strategies, and executes actions. Here’s a detailed breakdown of their roles:\\n\\n1. **Task Decomposition**: Planning allows the agent to break down complex tasks into smaller, manageable subgoals. This decomposition is essential for efficient handling of intricate tasks, enabling the agent to approach problems systematically. Techniques such as Chain of Thought (CoT) and Tree of Thoughts facilitate this process by encouraging the agent to think step-by-step and explore multiple reasoning possibilities at each stage.\\n\\n2. **Strategic Decision-Making**: The planning component is responsible for generating a sequence of actions that the agent should take to achieve its goals. This involves evaluating different options, predicting outcomes, and selecting the most effective course of action. The agent must consider various factors, including the current context, available resources, and potential obstacles, to make informed decisions.\\n\\n3. **Self-Reflection and Learning**: Decision-making is enhanced through self-reflection, where the agent evaluates past actions and their outcomes. This iterative process allows the agent to learn from mistakes and refine its strategies for future tasks. By reflecting on previous experiences, the agent can improve its decision-making capabilities, leading to better performance over time.\\n\\n4. **Dynamic Adaptation**: In a dynamic environment, the agent must adapt its plans in real-time based on new information or changes in context. Effective decision-making enables the agent to reassess its strategies and modify its actions accordingly, ensuring that it remains responsive to its surroundings.\\n\\n5. **Integration with Perception**: Decision-making and planning are closely linked to the agent's perception capabilities. The agent relies on sensory data to inform its understanding of the environment, which in turn influences its planning and decision-making processes. By integrating perception with planning, the agent can generate contextually appropriate responses and actions.\\n\\n6. **Handling Complexity and Uncertainty**: The architecture must account for the inherent complexity and uncertainty in real-world tasks. Planning mechanisms help the agent navigate these challenges by providing structured approaches to problem-solving, even when faced with unexpected errors or ambiguous situations.\\n\\nIn summary, decision-making and planning are critical for the effective functioning of an LLM-based autonomous agent system. They enable the agent to break down tasks, make informed choices, learn from experiences, adapt to changes, and integrate sensory information, all of which contribute to the agent's ability to operate autonomously and efficiently in complex environments.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer individually\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer each sub-question individually\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# RAG prompt\n",
    "prompt_rag = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "\n",
    "def retrieve_and_rag(question, prompt_rag, sub_question_generator_chain):\n",
    "    \"\"\"RAG on each sub-question\"\"\"\n",
    "\n",
    "    # Use our decomposition /\n",
    "    sub_questions = sub_question_generator_chain.invoke({\"question\": question})\n",
    "\n",
    "    # Initialize a list to hold RAG chain results\n",
    "    rag_results = []\n",
    "\n",
    "    for sub_question in sub_questions:\n",
    "\n",
    "        # Retrieve documents for each sub-question\n",
    "        retrieved_docs = retriever.invoke(sub_question)\n",
    "\n",
    "        # Use retrieved documents and sub-question in RAG chain\n",
    "        answer = (prompt_rag | model | StrOutputParser()).invoke(\n",
    "            {\"context\": retrieved_docs, \"question\": sub_question}\n",
    "        )\n",
    "        rag_results.append(answer)\n",
    "\n",
    "    return rag_results, sub_questions\n",
    "\n",
    "\n",
    "# Wrap the retrieval and RAG process in a RunnableLambda for integration into a chain\n",
    "answers, questions = retrieve_and_rag(\n",
    "    question, prompt_rag, generate_queries_decomposition\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'An LLM-powered autonomous agent system comprises several key components that work together to enable effective functioning. These components include:\\n\\n1. **Planning and Subgoal Decomposition**: The system is designed to break down complex tasks into manageable subgoals, allowing for efficient task handling and organization.\\n\\n2. **Decision-Making**: Decision-making processes are integral, utilizing techniques such as Chain of Thought (CoT) and Tree of Thoughts to explore various possibilities and refine approaches to tasks.\\n\\n3. **Perception and Sensor Integration**: The agent processes observations and events from its environment through a retrieval model, assessing the relevance and importance of these inputs to inform its behavior and planning.\\n\\n4. **Reflection and Refinement**: A reflection mechanism enables the agent to learn from past actions, synthesizing experiences into higher-level inferences that guide future decisions and improve overall performance.\\n\\n5. **Natural Language Interface**: The system incorporates a natural language interface to facilitate interaction with external components, such as memory and tools, enhancing communication and functionality.\\n\\nTogether, these components create a robust framework for an autonomous agent, allowing it to operate effectively in dynamic environments.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_qa_pairs(questions, answers):\n",
    "    \"\"\"Format Q and A pairs\"\"\"\n",
    "\n",
    "    formatted_string = \"\"\n",
    "    for i, (question, answer) in enumerate(zip(questions, answers), start=1):\n",
    "        formatted_string += f\"Question {i}: {question}\\nAnswer {i}: {answer}\\n\\n\"\n",
    "    return formatted_string.strip()\n",
    "\n",
    "\n",
    "context = format_qa_pairs(questions, answers)\n",
    "\n",
    "# Prompt\n",
    "template = \"\"\"Here is a set of Q+A pairs:\n",
    "\n",
    "{context}\n",
    "\n",
    "Use these to synthesize an answer to the question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "final_rag_chain = prompt | model | StrOutputParser()\n",
    "\n",
    "final_rag_chain.invoke({\"context\": context, \"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step back\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few Shot Examples\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"Could the members of The Police perform lawful arrests?\",\n",
    "        \"output\": \"what can the members of The Police do?\",\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Jan Šindel was born in what country?\",\n",
    "        \"output\": \"what is Jan Šindel's personal history?\",\n",
    "    },\n",
    "]\n",
    "# We now transform these to example messages\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are an expert at world knowledge. \n",
    "            Your task is to step back and paraphrase a question to a more generic step-back question, \n",
    "            which is easier to answer. Here are a few examples:\"\"\",\n",
    "        ),\n",
    "        # Few shot examples\n",
    "        few_shot_prompt,\n",
    "        # New question\n",
    "        (\"user\", \"{question}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what does task decomposition mean in the context of agents?'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_queries_step_back = prompt | model | StrOutputParser()\n",
    "question = \"What is task decomposition for LLM agents?\"\n",
    "generate_queries_step_back.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition for LLM (large language model) agents refers to the process of breaking down complex tasks into smaller, more manageable subgoals. This approach enhances the efficiency and effectiveness of the agent in handling intricate tasks. \\n\\nThere are several techniques and methodologies for task decomposition:\\n\\n1. **Chain of Thought (CoT)**: This technique encourages the model to \"think step by step,\" allowing it to utilize more computational resources at test time. By decomposing a large task into smaller, simpler steps, CoT not only facilitates task management but also provides insights into the model\\'s reasoning process.\\n\\n2. **Tree of Thoughts**: An extension of CoT, this method explores multiple reasoning possibilities at each step. It decomposes the problem into various thought steps and generates multiple thoughts for each step, forming a tree structure. The search process can be conducted using either breadth-first search (BFS) or depth-first search (DFS), with each state evaluated by a classifier or through majority voting.\\n\\n3. **Prompting Techniques**: Task decomposition can be initiated by prompting the LLM with specific instructions, such as asking for the steps to achieve a goal or identifying subgoals for a task. For example, prompts like \"Steps for XYZ\" or \"What are the subgoals for achieving XYZ?\" can guide the model in breaking down tasks.\\n\\n4. **Task-Specific Instructions**: Providing specific instructions tailored to the task at hand can also facilitate decomposition. For instance, asking the model to \"Write a story outline\" for a narrative task directs it to focus on relevant subgoals.\\n\\n5. **Human Inputs**: In some cases, human guidance can be utilized to assist the LLM in identifying and structuring subgoals effectively.\\n\\nOverall, task decomposition is a critical component of LLM-powered autonomous agents, enabling them to tackle complex problems systematically and improve their performance through structured planning and reflection.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Response prompt\n",
    "response_prompt_template = \"\"\"\n",
    "You are an expert of world knowledge. \n",
    "I am going to ask you a question. \n",
    "Your response should be comprehensive and not contradicted with the following context if they are relevant. \n",
    "Otherwise, ignore them if they are not relevant.\n",
    "\n",
    "# {normal_context}\n",
    "# {step_back_context}\n",
    "\n",
    "# Original Question: {question}\n",
    "# Answer:\"\"\"\n",
    "response_prompt = ChatPromptTemplate.from_template(response_prompt_template)\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        # Retrieve context using the normal question\n",
    "        \"normal_context\": RunnableLambda(lambda x: x[\"question\"]) | retriever,\n",
    "        # Retrieve context using the step-back question\n",
    "        \"step_back_context\": generate_queries_step_back | retriever,\n",
    "        # Pass on the question\n",
    "        \"question\": lambda x: x[\"question\"],\n",
    "    }\n",
    "    | response_prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HyDE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"**Task Decomposition for LLM Agents**\\n\\nTask decomposition is a critical process in the context of Large Language Model (LLM) agents, wherein complex tasks are systematically broken down into smaller, more manageable sub-tasks. This approach enhances the efficiency and effectiveness of LLMs in performing intricate operations that require multi-step reasoning or the integration of diverse knowledge domains. \\n\\nIn the realm of artificial intelligence, particularly with LLMs, task decomposition serves several key purposes. Firstly, it allows for the simplification of problem-solving by enabling the model to focus on one aspect of a task at a time, thereby reducing cognitive load and minimizing the risk of errors. For instance, when tasked with generating a comprehensive report, an LLM can decompose the task into distinct components such as data collection, analysis, and synthesis of findings, allowing for a more structured and coherent output.\\n\\nSecondly, task decomposition facilitates the identification of dependencies among sub-tasks, which is essential for optimizing the sequence of operations. By understanding which tasks must precede others, LLM agents can prioritize their processing, leading to improved performance and reduced latency. This is particularly relevant in applications such as dialogue systems, where maintaining context and coherence across multiple turns of conversation is crucial.\\n\\nMoreover, task decomposition can enhance the interpretability of LLM outputs. By breaking down tasks, researchers and developers can better trace the decision-making process of the model, allowing for more transparent evaluations of its reasoning and outputs. This is vital for applications in sensitive domains such as healthcare or legal systems, where understanding the rationale behind a model's conclusions is paramount.\\n\\nIn practice, implementing task decomposition in LLM agents often involves the use of prompt engineering techniques, where specific instructions are crafted to guide the model through the various stages of a task. This can include providing explicit cues for each sub-task or utilizing iterative prompting strategies that build upon previous outputs. \\n\\nIn conclusion, task decomposition is an essential strategy for enhancing the capabilities of LLM agents, enabling them to tackle complex tasks with greater precision and clarity. As the field of artificial intelligence continues to evolve, further research into effective decomposition methods will be crucial for unlocking the full potential of LLMs in diverse applications.\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# HyDE document genration\n",
    "template = \"\"\"Please write a scientific paper passage to answer the question\n",
    "Question: {question}\n",
    "Passage:\"\"\"\n",
    "prompt_hyde = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "generate_docs_for_retrieval = prompt_hyde | model | StrOutputParser()\n",
    "\n",
    "# Run\n",
    "question = \"What is task decomposition for LLM agents?\"\n",
    "generate_docs_for_retrieval.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'),\n",
       " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'),\n",
       " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\n\\n\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.\\n\\n\\nReliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. https://lilianweng.github.io/posts/2023-06-23-agent/.'),\n",
       " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='The AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can\\'t be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.\\n\\n(2) Model selection: LLM distributes the tasks to expert models, where the request is framed as a multiple-choice question. LLM is presented with a list of models to choose from. Due to the limited context length, task type based filtration is needed.\\nInstruction:')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve\n",
    "retrieval_chain = generate_docs_for_retrieval | retriever\n",
    "retrieved_docs = retrieval_chain.invoke({\"question\": question})\n",
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition for LLM (large language model) agents involves breaking down complex tasks into smaller, manageable subgoals. This process enables the agent to handle complicated tasks more efficiently. There are several methods for task decomposition:\\n\\n1. **Chain of Thought (CoT)**: This technique encourages the model to \"think step by step,\" allowing it to utilize more computation at test time to decompose hard tasks into simpler steps. CoT transforms large tasks into multiple manageable tasks and provides insight into the model\\'s reasoning process.\\n\\n2. **Tree of Thoughts**: This method extends CoT by exploring multiple reasoning possibilities at each step. It decomposes the problem into multiple thought steps and generates various thoughts per step, creating a tree structure. The search process can be conducted using breadth-first search (BFS) or depth-first search (DFS), with each state evaluated by a classifier or through majority voting.\\n\\n3. **Prompting and Instructions**: Task decomposition can also be achieved through simple prompting (e.g., asking for steps to achieve a goal), task-specific instructions (e.g., \"Write a story outline\"), or human inputs.\\n\\nOverall, task decomposition is a crucial component of planning in LLM-powered autonomous agents, allowing them to manage and execute complex tasks effectively.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RAG\n",
    "template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "final_rag_chain = prompt | model | StrOutputParser()\n",
    "\n",
    "final_rag_chain.invoke({\"context\": retrieved_docs, \"question\": question})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
