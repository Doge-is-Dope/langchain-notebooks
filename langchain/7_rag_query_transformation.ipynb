{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T14:46:30.289974Z",
     "start_time": "2024-06-29T14:46:30.286812Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Query\n",
    "\n",
    "### Index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "blog_docs = loader.load()\n",
    "\n",
    "# Split\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=300, chunk_overlap=50\n",
    ")\n",
    "\n",
    "# Make splits\n",
    "splits = text_splitter.split_documents(blog_docs)\n",
    "\n",
    "# Index\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\"),\n",
    ")\n",
    "\n",
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Multi Query: Different Perspectives\n",
    "template = \"\"\"You are an AI language model assistant. Your task is to generate five \n",
    "different versions of the given user question to retrieve relevant documents from a vector \n",
    "database. By generating multiple perspectives on the user question, your goal is to help\n",
    "the user overcome some of the limitations of the distance-based similarity search. \n",
    "Provide these alternative questions separated by newlines. Original question: {question}\"\"\"\n",
    "prompt_perspectives = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "generate_queries = (\n",
    "    prompt_perspectives\n",
    "    | ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    | StrOutputParser()\n",
    "    | (lambda x: x.split(\"\\n\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/clement/Developer/ai/langchain-notebooks/.venv/lib/python3.11/site-packages/langchain_core/_api/beta_decorator.py:87: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
      "  warn_beta(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.load import dumps, loads\n",
    "\n",
    "\n",
    "def get_unique_union(documents: list[list]):\n",
    "    \"\"\"Unique union of retrieved docs\"\"\"\n",
    "    # Flatten list of lists, and convert each Document to string\n",
    "    flattened_docs = [dumps(doc) for sublist in documents for doc in sublist]\n",
    "    # Get unique documents\n",
    "    unique_docs = list(set(flattened_docs))\n",
    "    # Return\n",
    "    return [loads(doc) for doc in unique_docs]\n",
    "\n",
    "\n",
    "# Retrieve\n",
    "question = \"What is task decomposition for LLM agents?\"\n",
    "retrieval_chain = generate_queries | retriever.map() | get_unique_union\n",
    "docs = retrieval_chain.invoke({\"question\": question})\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition for LLM (large language model) agents involves breaking down complex tasks into smaller, manageable subgoals. This process enables the agent to handle complicated tasks more efficiently. One common technique used for task decomposition is Chain of Thought (CoT) prompting, where the model is instructed to \"think step by step,\" allowing it to transform large tasks into simpler, more manageable steps. \\n\\nAdditionally, the Tree of Thoughts approach extends CoT by exploring multiple reasoning possibilities at each step, creating a tree structure of thought processes. This method allows the agent to evaluate different paths through either breadth-first search (BFS) or depth-first search (DFS), enhancing its ability to navigate complex problem-solving scenarios.\\n\\nTask decomposition can be achieved through various means, including simple prompting, task-specific instructions, or human inputs, all aimed at facilitating the agent\\'s planning and execution of tasks.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# RAG\n",
    "template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "final_rag_chain = (\n",
    "    {\"context\": retrieval_chain, \"question\": itemgetter(\"question\")}\n",
    "    | prompt\n",
    "    | ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "final_rag_chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG-Fusion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# RAG-Fusion: Related\n",
    "template = \"\"\"You are a helpful assistant that generates multiple search queries based on a single input query. \\n\n",
    "Generate multiple search queries related to: {question} \\n\n",
    "Output (4 queries):\"\"\"\n",
    "prompt_rag_fusion = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "generate_queries = (\n",
    "    prompt_rag_fusion | model | StrOutputParser() | (lambda x: x.split(\"\\n\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.load import dumps, loads\n",
    "\n",
    "\n",
    "def reciprocal_rank_fusion(results: list[list], k=60):\n",
    "    \"\"\"Reciprocal_rank_fusion that takes multiple lists of ranked documents\n",
    "    and an optional parameter k used in the RRF formula\"\"\"\n",
    "\n",
    "    # Initialize a dictionary to hold fused scores for each unique document\n",
    "    fused_scores = {}\n",
    "\n",
    "    # Iterate through each list of ranked documents\n",
    "    for docs in results:\n",
    "        # Iterate through each document in the list, with its rank (position in the list)\n",
    "        for rank, doc in enumerate(docs):\n",
    "            # Convert the document to a string format to use as a key (assumes documents can be serialized to JSON)\n",
    "            doc_str = dumps(doc)\n",
    "            # If the document is not yet in the fused_scores dictionary, add it with an initial score of 0\n",
    "            if doc_str not in fused_scores:\n",
    "                fused_scores[doc_str] = 0\n",
    "            # Retrieve the current score of the document, if any\n",
    "            previous_score = fused_scores[doc_str]\n",
    "            # Update the score of the document using the RRF formula: 1 / (rank + k)\n",
    "            fused_scores[doc_str] += 1 / (rank + k)\n",
    "\n",
    "    # Sort the documents based on their fused scores in descending order to get the final reranked results\n",
    "    reranked_results = [\n",
    "        (loads(doc), score)\n",
    "        for doc, score in sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    ]\n",
    "\n",
    "    # Return the reranked results as a list of tuples, each containing the document and its fused score\n",
    "    return reranked_results\n",
    "\n",
    "\n",
    "retrieval_chain_rag_fusion = generate_queries | retriever.map() | reciprocal_rank_fusion\n",
    "docs = retrieval_chain_rag_fusion.invoke({\"question\": question})\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition for LLM (large language model) agents involves breaking down complex tasks into smaller, manageable subgoals. This process enables the agent to handle complicated tasks more efficiently. There are several methods for task decomposition:\\n\\n1. **Prompting**: The LLM can be prompted with simple instructions like \"Steps for XYZ\" or \"What are the subgoals for achieving XYZ?\" to guide the decomposition process.\\n\\n2. **Task-specific instructions**: The agent can use specific instructions tailored to the task at hand, such as \"Write a story outline\" for writing a novel.\\n\\n3. **Human inputs**: Human guidance can also be utilized to assist in breaking down tasks.\\n\\nAdditionally, techniques like Chain of Thought (CoT) and Tree of Thoughts extend the capabilities of task decomposition. CoT encourages the model to think step by step, while Tree of Thoughts explores multiple reasoning possibilities at each step, creating a tree structure for more comprehensive planning.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# RAG\n",
    "template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "final_rag_chain = (\n",
    "    {\"context\": retrieval_chain_rag_fusion, \"question\": itemgetter(\"question\")}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "final_rag_chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decomposition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Decomposition\n",
    "template = \"\"\"You are a helpful assistant that generates multiple sub-questions related to an input question. \\n\n",
    "The goal is to break down the input into a set of sub-problems / sub-questions that can be answers in isolation. \\n\n",
    "Generate multiple search queries related to: {question} \\n\n",
    "Output (3 queries):\"\"\"\n",
    "prompt_decomposition = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# LLM\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Chain\n",
    "generate_queries_decomposition = (\n",
    "    prompt_decomposition | model | StrOutputParser() | (lambda x: x.split(\"\\n\"))\n",
    ")\n",
    "\n",
    "# Run\n",
    "question = \"What are the main components of an LLM-powered autonomous agent system?\"\n",
    "questions = generate_queries_decomposition.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. What are the key components of a large language model (LLM) in an autonomous agent system?',\n",
       " '2. How do perception and sensor integration function within an LLM-powered autonomous agent?',\n",
       " '3. What role does decision-making and planning play in the architecture of an LLM-based autonomous agent system?']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "template = \"\"\"Here is the question you need to answer:\n",
    "\n",
    "\\n --- \\n {question} \\n --- \\n\n",
    "\n",
    "Here is any available background question + answer pairs:\n",
    "\n",
    "\\n --- \\n {q_a_pairs} \\n --- \\n\n",
    "\n",
    "Here is additional context relevant to the question: \n",
    "\n",
    "\\n --- \\n {context} \\n --- \\n\n",
    "\n",
    "Use the above context and any background question + answer pairs to answer the question: \\n {question}\n",
    "\"\"\"\n",
    "\n",
    "decomposition_prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "def format_qa_pair(question, answer):\n",
    "    \"\"\"Format Q and A pair\"\"\"\n",
    "\n",
    "    formatted_string = \"\"\n",
    "    formatted_string += f\"Question: {question}\\nAnswer: {answer}\\n\\n\"\n",
    "    return formatted_string.strip()\n",
    "\n",
    "\n",
    "q_a_pairs = \"\"\n",
    "for q in questions:\n",
    "    rag_chain = (\n",
    "        {\n",
    "            \"context\": itemgetter(\"question\") | retriever,\n",
    "            \"question\": itemgetter(\"question\"),\n",
    "            \"q_a_pairs\": itemgetter(\"q_a_pairs\"),\n",
    "        }\n",
    "        | decomposition_prompt\n",
    "        | model\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    answer = rag_chain.invoke({\"question\": q, \"q_a_pairs\": q_a_pairs})\n",
    "    q_a_pair = format_qa_pair(q, answer)\n",
    "    q_a_pairs = q_a_pairs + \"\\n---\\n\" + q_a_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " \"Question: 1. What are the key components of a large language model (LLM) in an autonomous agent system?\\nAnswer: The key components of a large language model (LLM) in an autonomous agent system include:\\n\\n1. **Planning**: This involves the ability of the agent to break down complex tasks into smaller, manageable subgoals. Effective planning is crucial for handling complicated tasks efficiently.\\n\\n2. **Subgoal and Decomposition**: The agent utilizes techniques such as Chain of Thought (CoT) and Tree of Thoughts to decompose tasks into simpler steps. CoT encourages the model to think step by step, while Tree of Thoughts explores multiple reasoning possibilities at each step, creating a structured approach to problem-solving.\\n\\n3. **Reflection and Refinement**: The agent can engage in self-criticism and reflection over past actions, allowing it to learn from mistakes and improve future performance. This iterative process enhances the quality of the results produced by the agent.\\n\\n4. **Memory**: The system may incorporate memory components to retain information over time, which can help in long-term planning and maintaining context. However, challenges exist due to the finite context length of LLMs, which limits their ability to include extensive historical information.\\n\\n5. **Natural Language Interface**: The interaction between the LLM and external components (like memory and tools) relies on natural language. This interface is essential for communication but can be prone to errors, affecting the reliability of the agent's outputs.\\n\\n6. **Challenges in Long-term Planning**: LLMs face difficulties in adjusting plans when unexpected errors occur, making them less robust compared to human problem solvers who can learn from trial and error.\\n\\nThese components work together to enable LLMs to function effectively as the core controller in autonomous agent systems, allowing them to tackle a variety of tasks and improve their performance over time.\",\n",
       " \"Question: 2. How do perception and sensor integration function within an LLM-powered autonomous agent?\\nAnswer: In an LLM-powered autonomous agent, perception and sensor integration play crucial roles in enabling the agent to interact effectively with its environment and make informed decisions. Here’s how these functions operate within the system:\\n\\n1. **Perception**: This refers to the agent's ability to interpret and understand sensory data from its environment. The agent receives observations or events, which are direct inputs that inform its understanding of the current state of the world. These observations can come from various sensors or data sources, such as cameras, microphones, or other input devices. The agent processes this sensory information to form a coherent picture of its surroundings, which is essential for planning and decision-making.\\n\\n2. **Sensor Integration**: This involves combining data from multiple sensors to create a comprehensive understanding of the environment. The integration process considers factors such as recency, importance, and relevance of the data. For instance, recent events may be weighted more heavily in the agent's decision-making process, while core memories are distinguished from mundane observations. This allows the agent to prioritize information that is most pertinent to its current tasks.\\n\\n3. **Reflection Mechanism**: The agent synthesizes its sensory experiences over time, creating higher-level inferences that guide future behavior. This reflection mechanism helps the agent learn from past interactions and adapt its strategies accordingly. By analyzing a set of recent observations, the agent can generate salient questions and derive insights that inform its planning and actions.\\n\\n4. **Planning and Reacting**: The agent translates its reflections and environmental information into actionable plans. This involves optimizing its responses based on the current context and the information gathered from its sensors. The planning process is dynamic, allowing the agent to adjust its actions in real-time based on new sensory inputs.\\n\\n5. **Natural Language Interface**: The integration of perception and sensor data is often facilitated through a natural language interface, which allows the agent to communicate its understanding and intentions. However, the reliability of this interface can be a challenge, as it may lead to errors in interpreting or executing commands.\\n\\nIn summary, perception and sensor integration within an LLM-powered autonomous agent enable it to gather, process, and utilize environmental data effectively. This capability is essential for the agent to plan, react, and learn from its experiences, ultimately enhancing its performance in complex tasks.\",\n",
       " \"Question: 3. What role does decision-making and planning play in the architecture of an LLM-based autonomous agent system?\\nAnswer: Decision-making and planning are fundamental components of the architecture of an LLM-based autonomous agent system, serving as the backbone for how the agent interprets tasks, formulates strategies, and executes actions. Here’s a detailed breakdown of their roles:\\n\\n1. **Task Decomposition**: Effective planning allows the agent to break down complex tasks into smaller, manageable subgoals. This decomposition is essential for handling intricate tasks efficiently, as it transforms large, daunting objectives into simpler steps that can be tackled sequentially. Techniques like Chain of Thought (CoT) and Tree of Thoughts facilitate this process by encouraging the agent to think step by step and explore multiple reasoning possibilities at each stage.\\n\\n2. **Dynamic Decision-Making**: The agent's ability to make decisions is closely tied to its planning capabilities. As the agent gathers information from its environment through perception and sensor integration, it must evaluate this data to make informed choices about its next actions. This decision-making process is dynamic, allowing the agent to adjust its plans in real-time based on new sensory inputs and reflections on past experiences.\\n\\n3. **Self-Reflection and Refinement**: Decision-making is not a one-time process; it involves continuous self-reflection. The agent can analyze its previous actions, learn from mistakes, and refine its strategies for future tasks. This iterative improvement enhances the overall quality of the agent's performance, making it more adept at navigating complex scenarios.\\n\\n4. **Long-Term Planning**: While LLMs can engage in short-term planning effectively, they face challenges with long-term planning due to their finite context length and difficulties in adjusting plans when unexpected errors occur. This limitation necessitates the integration of external planning tools or frameworks, such as classical planners that utilize Planning Domain Definition Language (PDDL), to assist in generating comprehensive plans for more complex tasks.\\n\\n5. **Natural Language Interface**: The interaction between the LLM and its planning components often relies on a natural language interface. This interface is crucial for translating the agent's plans and decisions into understandable commands and actions. However, the reliability of this interface can be problematic, as errors in interpretation or execution can arise, impacting the effectiveness of the agent's decision-making process.\\n\\nIn summary, decision-making and planning are integral to the functionality of LLM-based autonomous agents. They enable the agent to decompose tasks, make informed choices, reflect on past actions, and adapt to new information, all of which are essential for successfully navigating complex environments and achieving desired outcomes.\"]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_a_pairs.split(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Decision-making and planning are fundamental components of the architecture of an LLM-based autonomous agent system, serving as the backbone for how the agent interprets tasks, formulates strategies, and executes actions. Here’s a detailed breakdown of their roles:\\n\\n1. **Task Decomposition**: Effective planning allows the agent to break down complex tasks into smaller, manageable subgoals. This decomposition is essential for handling intricate tasks efficiently, as it transforms large, daunting objectives into simpler steps that can be tackled sequentially. Techniques like Chain of Thought (CoT) and Tree of Thoughts facilitate this process by encouraging the agent to think step by step and explore multiple reasoning possibilities at each stage.\\n\\n2. **Dynamic Decision-Making**: The agent's ability to make decisions is closely tied to its planning capabilities. As the agent gathers information from its environment through perception and sensor integration, it must evaluate this data to make informed choices about its next actions. This decision-making process is dynamic, allowing the agent to adjust its plans in real-time based on new sensory inputs and reflections on past experiences.\\n\\n3. **Self-Reflection and Refinement**: Decision-making is not a one-time process; it involves continuous self-reflection. The agent can analyze its previous actions, learn from mistakes, and refine its strategies for future tasks. This iterative improvement enhances the overall quality of the agent's performance, making it more adept at navigating complex scenarios.\\n\\n4. **Long-Term Planning**: While LLMs can engage in short-term planning effectively, they face challenges with long-term planning due to their finite context length and difficulties in adjusting plans when unexpected errors occur. This limitation necessitates the integration of external planning tools or frameworks, such as classical planners that utilize Planning Domain Definition Language (PDDL), to assist in generating comprehensive plans for more complex tasks.\\n\\n5. **Natural Language Interface**: The interaction between the LLM and its planning components often relies on a natural language interface. This interface is crucial for translating the agent's plans and decisions into understandable commands and actions. However, the reliability of this interface can be problematic, as errors in interpretation or execution can arise, impacting the effectiveness of the agent's decision-making process.\\n\\nIn summary, decision-making and planning are integral to the functionality of LLM-based autonomous agents. They enable the agent to decompose tasks, make informed choices, reflect on past actions, and adapt to new information, all of which are essential for successfully navigating complex environments and achieving desired outcomes.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer individually\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer each sub-question individually\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# RAG prompt\n",
    "prompt_rag = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "\n",
    "def retrieve_and_rag(question, prompt_rag, sub_question_generator_chain):\n",
    "    \"\"\"RAG on each sub-question\"\"\"\n",
    "\n",
    "    # Use our decomposition /\n",
    "    sub_questions = sub_question_generator_chain.invoke({\"question\": question})\n",
    "\n",
    "    # Initialize a list to hold RAG chain results\n",
    "    rag_results = []\n",
    "\n",
    "    for sub_question in sub_questions:\n",
    "\n",
    "        # Retrieve documents for each sub-question\n",
    "        retrieved_docs = retriever.invoke(sub_question)\n",
    "\n",
    "        # Use retrieved documents and sub-question in RAG chain\n",
    "        answer = (prompt_rag | model | StrOutputParser()).invoke(\n",
    "            {\"context\": retrieved_docs, \"question\": sub_question}\n",
    "        )\n",
    "        rag_results.append(answer)\n",
    "\n",
    "    return rag_results, sub_questions\n",
    "\n",
    "\n",
    "# Wrap the retrieval and RAG process in a RunnableLambda for integration into a chain\n",
    "answers, questions = retrieve_and_rag(\n",
    "    question, prompt_rag, generate_queries_decomposition\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The main components of an LLM-powered autonomous agent system include:\\n\\n1. **Large Language Model (LLM)**: The core of the system, responsible for processing natural language input and generating responses. It serves as the controller that interprets sensory data and plans actions.\\n\\n2. **Planning and Task Decomposition**: This involves breaking down complex tasks into manageable subgoals, which facilitates efficient execution and helps the agent navigate through various tasks systematically.\\n\\n3. **Decision-Making**: Critical for evaluating different options and determining the best course of action. Techniques such as Chain of Thought (CoT) and Tree of Thoughts enhance the agent's reasoning capabilities, allowing it to consider multiple possibilities.\\n\\n4. **Self-Reflection**: This component enables the agent to learn from past actions and mistakes, improving its performance and decision-making over time.\\n\\n5. **Perception and Sensory Input Integration**: The system incorporates mechanisms to process sensory data, allowing the agent to adapt its actions based on real-time information and environmental changes.\\n\\nTogether, these components create a robust framework for autonomous agents, enabling them to operate effectively in dynamic environments while continuously learning and improving.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_qa_pairs(questions, answers):\n",
    "    \"\"\"Format Q and A pairs\"\"\"\n",
    "\n",
    "    formatted_string = \"\"\n",
    "    for i, (question, answer) in enumerate(zip(questions, answers), start=1):\n",
    "        formatted_string += f\"Question {i}: {question}\\nAnswer {i}: {answer}\\n\\n\"\n",
    "    return formatted_string.strip()\n",
    "\n",
    "\n",
    "context = format_qa_pairs(questions, answers)\n",
    "\n",
    "# Prompt\n",
    "template = \"\"\"Here is a set of Q+A pairs:\n",
    "\n",
    "{context}\n",
    "\n",
    "Use these to synthesize an answer to the question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "final_rag_chain = prompt | model | StrOutputParser()\n",
    "\n",
    "final_rag_chain.invoke({\"context\": context, \"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step back\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few Shot Examples\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"Could the members of The Police perform lawful arrests?\",\n",
    "        \"output\": \"what can the members of The Police do?\",\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Jan Šindel was born in what country?\",\n",
    "        \"output\": \"what is Jan Šindel's personal history?\",\n",
    "    },\n",
    "]\n",
    "# We now transform these to example messages\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are an expert at world knowledge. \n",
    "            Your task is to step back and paraphrase a question to a more generic step-back question, \n",
    "            which is easier to answer. Here are a few examples:\"\"\",\n",
    "        ),\n",
    "        # Few shot examples\n",
    "        few_shot_prompt,\n",
    "        # New question\n",
    "        (\"user\", \"{question}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what does task decomposition mean in the context of agents?'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_queries_step_back = prompt | model | StrOutputParser()\n",
    "question = \"What is task decomposition for LLM agents?\"\n",
    "generate_queries_step_back.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition for LLM (large language model) agents refers to the process of breaking down complex tasks into smaller, more manageable subgoals. This approach enhances the efficiency and effectiveness of the agent in handling intricate tasks. \\n\\nThere are several techniques and methodologies for task decomposition:\\n\\n1. **Chain of Thought (CoT)**: This technique encourages the model to \"think step by step,\" allowing it to utilize more computational resources at test time. By decomposing a large task into smaller, simpler steps, CoT not only facilitates task management but also provides insights into the model\\'s reasoning process.\\n\\n2. **Tree of Thoughts**: An extension of CoT, this method explores multiple reasoning possibilities at each step. It decomposes the problem into various thought steps and generates multiple thoughts for each step, forming a tree structure. The search process can be conducted using either breadth-first search (BFS) or depth-first search (DFS), with each state evaluated by a classifier or through majority voting.\\n\\n3. **Prompting Techniques**: Task decomposition can be initiated by prompting the LLM with specific questions or instructions, such as asking for the steps to achieve a goal or identifying subgoals for a task. This can also include task-specific instructions tailored to particular activities, like writing a story outline.\\n\\n4. **Human Inputs**: In some cases, human guidance can be used to assist in breaking down tasks, providing additional context or direction that the model may not inherently possess.\\n\\nOverall, task decomposition is a critical component of LLM-powered autonomous agents, enabling them to tackle complex problems systematically and improve their performance through structured planning and reflection.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Response prompt\n",
    "response_prompt_template = \"\"\"\n",
    "You are an expert of world knowledge. \n",
    "I am going to ask you a question. \n",
    "Your response should be comprehensive and not contradicted with the following context if they are relevant. \n",
    "Otherwise, ignore them if they are not relevant.\n",
    "\n",
    "# {normal_context}\n",
    "# {step_back_context}\n",
    "\n",
    "# Original Question: {question}\n",
    "# Answer:\"\"\"\n",
    "response_prompt = ChatPromptTemplate.from_template(response_prompt_template)\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        # Retrieve context using the normal question\n",
    "        \"normal_context\": RunnableLambda(lambda x: x[\"question\"]) | retriever,\n",
    "        # Retrieve context using the step-back question\n",
    "        \"step_back_context\": generate_queries_step_back | retriever,\n",
    "        # Pass on the question\n",
    "        \"question\": lambda x: x[\"question\"],\n",
    "    }\n",
    "    | response_prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HyDE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"**Task Decomposition for LLM Agents**\\n\\nTask decomposition is a critical process in the context of Large Language Model (LLM) agents, wherein complex tasks are systematically broken down into smaller, more manageable sub-tasks. This approach enhances the efficiency and effectiveness of LLMs in performing intricate operations that require multi-step reasoning or the integration of diverse knowledge domains. \\n\\nIn the realm of artificial intelligence, particularly with LLMs, task decomposition serves several key purposes. Firstly, it allows for the simplification of problem-solving by enabling the model to focus on one aspect of a task at a time, thereby reducing cognitive load and minimizing the risk of errors. For instance, when tasked with generating a comprehensive report, an LLM can decompose the task into distinct components such as data collection, analysis, and synthesis of findings, allowing for a more structured and coherent output.\\n\\nSecondly, task decomposition facilitates the identification of dependencies among sub-tasks, which is crucial for optimizing the sequence of operations. By understanding which tasks must precede others, LLM agents can prioritize their processing, leading to improved performance and reduced latency in task completion. This is particularly relevant in applications such as dialogue systems, where maintaining context and coherence across multiple turns of conversation is essential.\\n\\nMoreover, task decomposition can enhance the interpretability of LLM outputs. By breaking down tasks, researchers and developers can better trace the decision-making process of the model, allowing for more transparent evaluations of its reasoning and outputs. This is vital for applications in sensitive domains such as healthcare or legal advice, where understanding the rationale behind a model's conclusions is paramount.\\n\\nIn practice, implementing task decomposition in LLM agents often involves the use of prompt engineering techniques, where specific instructions are crafted to guide the model through the decomposition process. This can include explicit requests for step-by-step reasoning or the use of templates that outline the necessary components of a task. As LLMs continue to evolve, the integration of advanced task decomposition strategies will likely play a pivotal role in enhancing their capabilities and applicability across various fields.\\n\\nIn conclusion, task decomposition is an essential strategy for optimizing the performance of LLM agents, enabling them to tackle complex tasks with greater efficiency, clarity, and reliability. As research in this area progresses, it is expected that more sophisticated methods for task decomposition will emerge, further expanding the potential of LLMs in real-world applications.\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# HyDE document genration\n",
    "template = \"\"\"Please write a scientific paper passage to answer the question\n",
    "Question: {question}\n",
    "Passage:\"\"\"\n",
    "prompt_hyde = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "generate_docs_for_retrieval = prompt_hyde | model | StrOutputParser()\n",
    "\n",
    "# Run\n",
    "question = \"What is task decomposition for LLM agents?\"\n",
    "generate_docs_for_retrieval.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'),\n",
       " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'),\n",
       " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\n\\n\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.\\n\\n\\nReliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. https://lilianweng.github.io/posts/2023-06-23-agent/.'),\n",
       " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='The AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can\\'t be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.\\n\\n(2) Model selection: LLM distributes the tasks to expert models, where the request is framed as a multiple-choice question. LLM is presented with a list of models to choose from. Due to the limited context length, task type based filtration is needed.\\nInstruction:')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve\n",
    "retrieval_chain = generate_docs_for_retrieval | retriever\n",
    "retrieved_docs = retrieval_chain.invoke({\"question\": question})\n",
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition for LLM (large language model) agents involves breaking down complex tasks into smaller, manageable subgoals. This process enables the agent to handle complicated tasks more efficiently. There are several methods for task decomposition:\\n\\n1. **Chain of Thought (CoT)**: This technique encourages the model to \"think step by step,\" allowing it to utilize more computation at test time to decompose hard tasks into simpler steps. CoT transforms large tasks into multiple manageable tasks and provides insight into the model\\'s reasoning process.\\n\\n2. **Tree of Thoughts**: This method extends CoT by exploring multiple reasoning possibilities at each step. It decomposes the problem into multiple thought steps and generates various thoughts per step, creating a tree structure. The search process can be conducted using breadth-first search (BFS) or depth-first search (DFS), with each state evaluated by a classifier or through majority voting.\\n\\n3. **Prompting Techniques**: Task decomposition can also be achieved through simple prompting, such as asking the model for the steps needed to accomplish a task or what subgoals are necessary. Additionally, task-specific instructions can guide the model, such as requesting a story outline for writing a novel.\\n\\n4. **Human Inputs**: Human guidance can also play a role in task decomposition, providing insights or directions that help the agent break down tasks effectively.\\n\\nOverall, task decomposition is a critical component of planning in LLM-powered autonomous agents, allowing them to manage and execute complex tasks more effectively.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RAG\n",
    "template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "final_rag_chain = prompt | model | StrOutputParser()\n",
    "\n",
    "final_rag_chain.invoke({\"context\": retrieved_docs, \"question\": question})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
