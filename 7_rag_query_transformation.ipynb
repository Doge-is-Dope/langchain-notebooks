{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T14:46:30.289974Z",
     "start_time": "2024-06-29T14:46:30.286812Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Query\n",
    "\n",
    "### Index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "blog_docs = loader.load()\n",
    "\n",
    "# Split\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=300, chunk_overlap=50\n",
    ")\n",
    "\n",
    "# Make splits\n",
    "splits = text_splitter.split_documents(blog_docs)\n",
    "\n",
    "# Index\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\"),\n",
    ")\n",
    "\n",
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Multi Query: Different Perspectives\n",
    "template = \"\"\"You are an AI language model assistant. Your task is to generate five \n",
    "different versions of the given user question to retrieve relevant documents from a vector \n",
    "database. By generating multiple perspectives on the user question, your goal is to help\n",
    "the user overcome some of the limitations of the distance-based similarity search. \n",
    "Provide these alternative questions separated by newlines. Original question: {question}\"\"\"\n",
    "prompt_perspectives = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "generate_queries = (\n",
    "    prompt_perspectives\n",
    "    | ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    | StrOutputParser()\n",
    "    | (lambda x: x.split(\"\\n\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/clement/Developer/ai/langchain-notebooks/.venv/lib/python3.11/site-packages/langchain_core/_api/beta_decorator.py:87: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
      "  warn_beta(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.load import dumps, loads\n",
    "\n",
    "\n",
    "def get_unique_union(documents: list[list]):\n",
    "    \"\"\"Unique union of retrieved docs\"\"\"\n",
    "    # Flatten list of lists, and convert each Document to string\n",
    "    flattened_docs = [dumps(doc) for sublist in documents for doc in sublist]\n",
    "    # Get unique documents\n",
    "    unique_docs = list(set(flattened_docs))\n",
    "    # Return\n",
    "    return [loads(doc) for doc in unique_docs]\n",
    "\n",
    "\n",
    "# Retrieve\n",
    "question = \"What is task decomposition for LLM agents?\"\n",
    "retrieval_chain = generate_queries | retriever.map() | get_unique_union\n",
    "docs = retrieval_chain.invoke({\"question\": question})\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition for LLM (large language model) agents involves breaking down complicated tasks into smaller, manageable subgoals. This process enhances the agent\\'s ability to handle complex tasks efficiently. Techniques such as Chain of Thought (CoT) prompting and the Tree of Thoughts approach are commonly used for task decomposition. \\n\\n- **Chain of Thought (CoT)**: This technique instructs the model to \"think step by step,\" allowing it to utilize more computational resources at test time to decompose hard tasks into simpler steps. It transforms large tasks into multiple manageable tasks and provides insight into the model\\'s reasoning process.\\n\\n- **Tree of Thoughts**: This method extends CoT by exploring multiple reasoning possibilities at each step. It decomposes the problem into several thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be conducted using breadth-first search (BFS) or depth-first search (DFS), with each state evaluated by a classifier or through majority voting.\\n\\nOverall, task decomposition can be achieved through simple prompting, task-specific instructions, or human inputs, enabling LLM agents to approach complex problems more effectively.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# RAG\n",
    "template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "final_rag_chain = (\n",
    "    {\"context\": retrieval_chain, \"question\": itemgetter(\"question\")}\n",
    "    | prompt\n",
    "    | ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "final_rag_chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG-Fusion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# RAG-Fusion: Related\n",
    "template = \"\"\"You are a helpful assistant that generates multiple search queries based on a single input query. \\n\n",
    "Generate multiple search queries related to: {question} \\n\n",
    "Output (4 queries):\"\"\"\n",
    "prompt_rag_fusion = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "generate_queries = (\n",
    "    prompt_rag_fusion | model | StrOutputParser() | (lambda x: x.split(\"\\n\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.load import dumps, loads\n",
    "\n",
    "\n",
    "def reciprocal_rank_fusion(results: list[list], k=60):\n",
    "    \"\"\"Reciprocal_rank_fusion that takes multiple lists of ranked documents\n",
    "    and an optional parameter k used in the RRF formula\"\"\"\n",
    "\n",
    "    # Initialize a dictionary to hold fused scores for each unique document\n",
    "    fused_scores = {}\n",
    "\n",
    "    # Iterate through each list of ranked documents\n",
    "    for docs in results:\n",
    "        # Iterate through each document in the list, with its rank (position in the list)\n",
    "        for rank, doc in enumerate(docs):\n",
    "            # Convert the document to a string format to use as a key (assumes documents can be serialized to JSON)\n",
    "            doc_str = dumps(doc)\n",
    "            # If the document is not yet in the fused_scores dictionary, add it with an initial score of 0\n",
    "            if doc_str not in fused_scores:\n",
    "                fused_scores[doc_str] = 0\n",
    "            # Retrieve the current score of the document, if any\n",
    "            previous_score = fused_scores[doc_str]\n",
    "            # Update the score of the document using the RRF formula: 1 / (rank + k)\n",
    "            fused_scores[doc_str] += 1 / (rank + k)\n",
    "\n",
    "    # Sort the documents based on their fused scores in descending order to get the final reranked results\n",
    "    reranked_results = [\n",
    "        (loads(doc), score)\n",
    "        for doc, score in sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    ]\n",
    "\n",
    "    # Return the reranked results as a list of tuples, each containing the document and its fused score\n",
    "    return reranked_results\n",
    "\n",
    "\n",
    "retrieval_chain_rag_fusion = generate_queries | retriever.map() | reciprocal_rank_fusion\n",
    "docs = retrieval_chain_rag_fusion.invoke({\"question\": question})\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition for LLM (large language model) agents involves breaking down complex tasks into smaller, manageable subgoals. This process enables the agent to handle complicated tasks more efficiently. There are several techniques for task decomposition:\\n\\n1. **Chain of Thought (CoT)**: This prompting technique encourages the model to \"think step by step,\" allowing it to decompose hard tasks into simpler steps, thereby enhancing performance and providing insight into the model\\'s reasoning process.\\n\\n2. **Tree of Thoughts**: This method extends CoT by exploring multiple reasoning possibilities at each step. It decomposes the problem into multiple thought steps and generates various thoughts per step, creating a tree structure that can be searched using breadth-first or depth-first search methods.\\n\\n3. **Prompting and Instructions**: Task decomposition can also be achieved through simple prompts (e.g., asking for steps to achieve a goal) or task-specific instructions (e.g., \"Write a story outline\" for writing a novel).\\n\\n4. **Human Inputs**: In some cases, human guidance can be used to help decompose tasks effectively.\\n\\nOverall, task decomposition is a critical component of planning in LLM-powered autonomous agents, allowing them to manage complex tasks more effectively.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# RAG\n",
    "template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "final_rag_chain = (\n",
    "    {\"context\": retrieval_chain_rag_fusion, \"question\": itemgetter(\"question\")}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "final_rag_chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decomposition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Decomposition\n",
    "template = \"\"\"You are a helpful assistant that generates multiple sub-questions related to an input question. \\n\n",
    "The goal is to break down the input into a set of sub-problems / sub-questions that can be answers in isolation. \\n\n",
    "Generate multiple search queries related to: {question} \\n\n",
    "Output (3 queries):\"\"\"\n",
    "prompt_decomposition = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# LLM\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Chain\n",
    "generate_queries_decomposition = (\n",
    "    prompt_decomposition | model | StrOutputParser() | (lambda x: x.split(\"\\n\"))\n",
    ")\n",
    "\n",
    "# Run\n",
    "question = \"What are the main components of an LLM-powered autonomous agent system?\"\n",
    "questions = generate_queries_decomposition.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. What are the key components of a large language model (LLM) in an autonomous agent system?',\n",
       " '2. How do perception and sensor integration function within an LLM-powered autonomous agent?',\n",
       " '3. What role does decision-making and planning play in the architecture of an LLM-based autonomous agent system?']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "template = \"\"\"Here is the question you need to answer:\n",
    "\n",
    "\\n --- \\n {question} \\n --- \\n\n",
    "\n",
    "Here is any available background question + answer pairs:\n",
    "\n",
    "\\n --- \\n {q_a_pairs} \\n --- \\n\n",
    "\n",
    "Here is additional context relevant to the question: \n",
    "\n",
    "\\n --- \\n {context} \\n --- \\n\n",
    "\n",
    "Use the above context and any background question + answer pairs to answer the question: \\n {question}\n",
    "\"\"\"\n",
    "\n",
    "decomposition_prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "def format_qa_pair(question, answer):\n",
    "    \"\"\"Format Q and A pair\"\"\"\n",
    "\n",
    "    formatted_string = \"\"\n",
    "    formatted_string += f\"Question: {question}\\nAnswer: {answer}\\n\\n\"\n",
    "    return formatted_string.strip()\n",
    "\n",
    "\n",
    "q_a_pairs = \"\"\n",
    "for q in questions:\n",
    "    rag_chain = (\n",
    "        {\n",
    "            \"context\": itemgetter(\"question\") | retriever,\n",
    "            \"question\": itemgetter(\"question\"),\n",
    "            \"q_a_pairs\": itemgetter(\"q_a_pairs\"),\n",
    "        }\n",
    "        | decomposition_prompt\n",
    "        | model\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    answer = rag_chain.invoke({\"question\": q, \"q_a_pairs\": q_a_pairs})\n",
    "    q_a_pair = format_qa_pair(q, answer)\n",
    "    q_a_pairs = q_a_pairs + \"\\n---\\n\" + q_a_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'Question: 1. What are the key components of a large language model (LLM) in an autonomous agent system?\\nAnswer: The key components of a large language model (LLM) in an autonomous agent system include:\\n\\n1. **Planning**: This involves the ability to break down complex tasks into smaller, manageable subgoals. Effective planning is crucial for handling complicated tasks efficiently.\\n\\n2. **Subgoal and Decomposition**: The agent can decompose large tasks into simpler steps, which allows for a structured approach to problem-solving. Techniques like Chain of Thought (CoT) and Tree of Thoughts enhance this capability by guiding the model to think step-by-step and explore multiple reasoning possibilities.\\n\\n3. **Reflection and Refinement**: The agent can engage in self-criticism and reflection on past actions, learning from mistakes to improve future performance. This iterative process helps refine the quality of the results produced by the agent.\\n\\n4. **Memory**: The system may incorporate memory components to retain information over time, which can aid in long-term planning and decision-making.\\n\\n5. **Natural Language Interface**: The LLM serves as the interface for communication between the agent and external components, such as memory and tools. However, the reliability of this interface can be a challenge due to potential formatting errors and inconsistencies in model outputs.\\n\\n6. **Context Management**: The LLM must operate within the constraints of its finite context length, which limits the amount of historical information it can consider. This necessitates careful design to maximize the effectiveness of the communication and planning processes.\\n\\nThese components work together to enable the LLM to function as a powerful general problem solver within an autonomous agent system.',\n",
       " \"Question: 2. How do perception and sensor integration function within an LLM-powered autonomous agent?\\nAnswer: In an LLM-powered autonomous agent, perception and sensor integration play crucial roles in enabling the agent to interact effectively with its environment and make informed decisions. Here’s how these functions operate within the system:\\n\\n1. **Perception**: This refers to the agent's ability to interpret and understand sensory data from its environment. The agent receives observations or events, which are direct inputs that inform its understanding of the current state of the world. These observations can come from various sensors or data sources, such as cameras, microphones, or other input devices. The agent processes this sensory information to form a coherent picture of its surroundings, which is essential for planning and decision-making.\\n\\n2. **Sensor Integration**: This involves combining data from multiple sensors to create a more comprehensive understanding of the environment. The integration process considers factors such as recency, importance, and relevance of the data. For instance, recent events may be weighted more heavily in the agent's decision-making process, while important events that are core to the agent's objectives are prioritized over mundane observations. This multi-sensor approach allows the agent to synthesize information and derive higher-level inferences, which guide its future behavior.\\n\\n3. **Reflection Mechanism**: The agent employs a reflection mechanism that synthesizes past observations into higher-level summaries. This process helps the agent learn from previous experiences and adapt its actions accordingly. By analyzing past events, the agent can identify patterns and make more informed decisions in similar future situations.\\n\\n4. **Planning and Reacting**: The agent translates its reflections and the integrated environmental information into actionable plans. This involves optimizing its responses based on the current context and the goals it aims to achieve. The planning process is dynamic, allowing the agent to adjust its strategies in real-time based on new sensory inputs and reflections.\\n\\nIn summary, perception and sensor integration within an LLM-powered autonomous agent enable it to gather, process, and interpret environmental data effectively. This capability is essential for the agent to plan actions, learn from experiences, and react appropriately to changes in its surroundings.\",\n",
       " 'Question: 3. What role does decision-making and planning play in the architecture of an LLM-based autonomous agent system?\\nAnswer: Decision-making and planning are fundamental components of the architecture of an LLM-based autonomous agent system, serving as the backbone for how the agent interprets tasks, formulates strategies, and executes actions. Here’s a detailed breakdown of their roles:\\n\\n1. **Task Decomposition**: Effective planning allows the agent to break down complex tasks into smaller, manageable subgoals. This decomposition is essential for handling intricate problems efficiently. Techniques such as Chain of Thought (CoT) and Tree of Thoughts enhance this capability by guiding the model to think step-by-step and explore multiple reasoning possibilities. By structuring tasks into simpler components, the agent can approach challenges methodically, improving its chances of success.\\n\\n2. **Dynamic Decision-Making**: The agent must make real-time decisions based on its understanding of the environment, which is informed by sensory data and past experiences. This involves evaluating the current context, integrating information from various sensors, and reflecting on previous actions to inform future choices. The ability to adapt plans dynamically in response to new information is crucial for effective operation in unpredictable environments.\\n\\n3. **Self-Reflection and Learning**: Decision-making is not just about immediate actions; it also involves a reflective process where the agent assesses the outcomes of its previous decisions. This self-reflection allows the agent to learn from mistakes and refine its strategies over time, leading to improved performance in future tasks. The iterative nature of this process is vital for continuous improvement and adaptation.\\n\\n4. **Memory Utilization**: Planning and decision-making are enhanced by the incorporation of memory components, which allow the agent to retain information over time. This long-term memory aids in decision-making by providing context and historical data that can inform current actions. However, the finite context length of LLMs poses challenges, as it limits the amount of historical information the agent can consider at any given time.\\n\\n5. **Integration with External Tools**: In some architectures, planning may be outsourced to external classical planners, which can handle long-horizon planning more effectively. The LLM translates the planning problem into a format that these planners can understand, facilitating a more structured approach to complex decision-making scenarios.\\n\\n6. **Reliability and Communication**: The natural language interface between the LLM and external components (like memory and tools) is crucial for effective planning and decision-making. However, the reliability of this interface can be problematic, as LLMs may produce formatting errors or exhibit unpredictable behavior. This necessitates careful design and parsing of model outputs to ensure that the planning and decision-making processes are robust.\\n\\nIn summary, decision-making and planning are integral to the functionality of LLM-based autonomous agents. They enable the agent to navigate complex tasks, adapt to changing environments, learn from experiences, and effectively communicate with external systems, all of which are essential for successful autonomous operation.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_a_pairs.split(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Decision-making and planning are fundamental components of the architecture of an LLM-based autonomous agent system, serving as the backbone for how the agent interprets tasks, formulates strategies, and executes actions. Here’s a detailed breakdown of their roles:\\n\\n1. **Task Decomposition**: Effective planning allows the agent to break down complex tasks into smaller, manageable subgoals. This decomposition is essential for handling intricate problems efficiently. Techniques such as Chain of Thought (CoT) and Tree of Thoughts enhance this capability by guiding the model to think step-by-step and explore multiple reasoning possibilities. By structuring tasks into simpler components, the agent can approach challenges methodically, improving its chances of success.\\n\\n2. **Dynamic Decision-Making**: The agent must make real-time decisions based on its understanding of the environment, which is informed by sensory data and past experiences. This involves evaluating the current context, integrating information from various sensors, and reflecting on previous actions to inform future choices. The ability to adapt plans dynamically in response to new information is crucial for effective operation in unpredictable environments.\\n\\n3. **Self-Reflection and Learning**: Decision-making is not just about immediate actions; it also involves a reflective process where the agent assesses the outcomes of its previous decisions. This self-reflection allows the agent to learn from mistakes and refine its strategies over time, leading to improved performance in future tasks. The iterative nature of this process is vital for continuous improvement and adaptation.\\n\\n4. **Memory Utilization**: Planning and decision-making are enhanced by the incorporation of memory components, which allow the agent to retain information over time. This long-term memory aids in decision-making by providing context and historical data that can inform current actions. However, the finite context length of LLMs poses challenges, as it limits the amount of historical information the agent can consider at any given time.\\n\\n5. **Integration with External Tools**: In some architectures, planning may be outsourced to external classical planners, which can handle long-horizon planning more effectively. The LLM translates the planning problem into a format that these planners can understand, facilitating a more structured approach to complex decision-making scenarios.\\n\\n6. **Reliability and Communication**: The natural language interface between the LLM and external components (like memory and tools) is crucial for effective planning and decision-making. However, the reliability of this interface can be problematic, as LLMs may produce formatting errors or exhibit unpredictable behavior. This necessitates careful design and parsing of model outputs to ensure that the planning and decision-making processes are robust.\\n\\nIn summary, decision-making and planning are integral to the functionality of LLM-based autonomous agents. They enable the agent to navigate complex tasks, adapt to changing environments, learn from experiences, and effectively communicate with external systems, all of which are essential for successful autonomous operation.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer individually\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer each sub-question individually\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# RAG prompt\n",
    "prompt_rag = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "\n",
    "def retrieve_and_rag(question, prompt_rag, sub_question_generator_chain):\n",
    "    \"\"\"RAG on each sub-question\"\"\"\n",
    "\n",
    "    # Use our decomposition /\n",
    "    sub_questions = sub_question_generator_chain.invoke({\"question\": question})\n",
    "\n",
    "    # Initialize a list to hold RAG chain results\n",
    "    rag_results = []\n",
    "\n",
    "    for sub_question in sub_questions:\n",
    "\n",
    "        # Retrieve documents for each sub-question\n",
    "        retrieved_docs = retriever.invoke(sub_question)\n",
    "\n",
    "        # Use retrieved documents and sub-question in RAG chain\n",
    "        answer = (prompt_rag | model | StrOutputParser()).invoke(\n",
    "            {\"context\": retrieved_docs, \"question\": sub_question}\n",
    "        )\n",
    "        rag_results.append(answer)\n",
    "\n",
    "    return rag_results, sub_questions\n",
    "\n",
    "\n",
    "# Wrap the retrieval and RAG process in a RunnableLambda for integration into a chain\n",
    "answers, questions = retrieve_and_rag(\n",
    "    question, prompt_rag, generate_queries_decomposition\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The main components of an LLM-powered autonomous agent system include:\\n\\n1. **Large Language Model (LLM)**: The core of the system, responsible for processing natural language input and generating responses. It serves as the primary controller, integrating sensory data and facilitating communication with external components.\\n\\n2. **Planning and Decision-Making**: This involves breaking down complex tasks into manageable subgoals, enabling efficient task execution. Techniques such as Chain of Thought (CoT) and Tree of Thoughts enhance the agent's reasoning capabilities, allowing it to explore multiple possibilities and refine its approach.\\n\\n3. **Subgoal Decomposition**: A critical aspect of planning, where the agent identifies smaller, achievable objectives that contribute to the overall task, making it easier to manage and execute complex actions.\\n\\n4. **Self-Reflection**: This component allows the agent to learn from past actions, improving its decision-making and planning capabilities over time. By reflecting on previous experiences, the agent can adapt its strategies and enhance performance.\\n\\n5. **Perception and Sensory Input Integration**: The system incorporates mechanisms to process sensory data, enabling the agent to respond to its environment effectively. This integration is essential for adapting to real-time changes and unexpected errors.\\n\\nTogether, these components create a robust framework for autonomous agents, allowing them to operate effectively in dynamic environments while continuously improving their performance.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_qa_pairs(questions, answers):\n",
    "    \"\"\"Format Q and A pairs\"\"\"\n",
    "\n",
    "    formatted_string = \"\"\n",
    "    for i, (question, answer) in enumerate(zip(questions, answers), start=1):\n",
    "        formatted_string += f\"Question {i}: {question}\\nAnswer {i}: {answer}\\n\\n\"\n",
    "    return formatted_string.strip()\n",
    "\n",
    "\n",
    "context = format_qa_pairs(questions, answers)\n",
    "\n",
    "# Prompt\n",
    "template = \"\"\"Here is a set of Q+A pairs:\n",
    "\n",
    "{context}\n",
    "\n",
    "Use these to synthesize an answer to the question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "final_rag_chain = prompt | model | StrOutputParser()\n",
    "\n",
    "final_rag_chain.invoke({\"context\": context, \"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step back\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few Shot Examples\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"Could the members of The Police perform lawful arrests?\",\n",
    "        \"output\": \"what can the members of The Police do?\",\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Jan Šindel was born in what country?\",\n",
    "        \"output\": \"what is Jan Šindel's personal history?\",\n",
    "    },\n",
    "]\n",
    "# We now transform these to example messages\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are an expert at world knowledge. \n",
    "            Your task is to step back and paraphrase a question to a more generic step-back question, \n",
    "            which is easier to answer. Here are a few examples:\"\"\",\n",
    "        ),\n",
    "        # Few shot examples\n",
    "        few_shot_prompt,\n",
    "        # New question\n",
    "        (\"user\", \"{question}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what does task decomposition mean in the context of agents?'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_queries_step_back = prompt | model | StrOutputParser()\n",
    "question = \"What is task decomposition for LLM agents?\"\n",
    "generate_queries_step_back.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition for LLM (large language model) agents refers to the process of breaking down complex tasks into smaller, more manageable subgoals. This approach enhances the efficiency and effectiveness of the agent in handling intricate tasks. \\n\\nThere are several techniques and methodologies for task decomposition:\\n\\n1. **Chain of Thought (CoT)**: This technique encourages the model to \"think step by step,\" allowing it to utilize more computational resources during the test phase. By decomposing a large task into smaller, simpler steps, CoT not only makes the task more manageable but also provides insights into the model\\'s reasoning process.\\n\\n2. **Tree of Thoughts**: An extension of CoT, this method involves exploring multiple reasoning possibilities at each step. The problem is first decomposed into various thought steps, and for each step, multiple thoughts are generated, creating a tree structure. This allows for a more comprehensive exploration of potential solutions, evaluated through methods like breadth-first search (BFS) or depth-first search (DFS).\\n\\n3. **Prompting Techniques**: Task decomposition can be initiated through simple prompts, such as asking the model to list the steps required to achieve a specific goal or to identify subgoals for a task. This can also include task-specific instructions tailored to particular activities, like writing a story outline.\\n\\n4. **Human Inputs**: In some cases, human guidance can be used to assist in breaking down tasks, providing additional context or direction that the model may not inherently possess.\\n\\nOverall, task decomposition is a critical component of LLM-powered autonomous agents, enabling them to tackle complex problems more effectively by structuring their approach into smaller, actionable parts.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Response prompt\n",
    "response_prompt_template = \"\"\"\n",
    "You are an expert of world knowledge. \n",
    "I am going to ask you a question. \n",
    "Your response should be comprehensive and not contradicted with the following context if they are relevant. \n",
    "Otherwise, ignore them if they are not relevant.\n",
    "\n",
    "# {normal_context}\n",
    "# {step_back_context}\n",
    "\n",
    "# Original Question: {question}\n",
    "# Answer:\"\"\"\n",
    "response_prompt = ChatPromptTemplate.from_template(response_prompt_template)\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        # Retrieve context using the normal question\n",
    "        \"normal_context\": RunnableLambda(lambda x: x[\"question\"]) | retriever,\n",
    "        # Retrieve context using the step-back question\n",
    "        \"step_back_context\": generate_queries_step_back | retriever,\n",
    "        # Pass on the question\n",
    "        \"question\": lambda x: x[\"question\"],\n",
    "    }\n",
    "    | response_prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain.invoke({\"question\": question})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
